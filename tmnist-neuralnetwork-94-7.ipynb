{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2830968,"sourceType":"datasetVersion","datasetId":1564532}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"###  Neural Network Tutorial for TMNIST Alphabet Character Classification\n\nThis guide will demonstrate how to develop and train a straightforward neural network to classify handwritten characters from the TMNIST Alphabet dataset, which encompasses 94 distinct characters.\n\n###  Abstract\n\nThe aim of this tutorial is to guide you through the steps needed to create and train a neural network that can accurately recognize and classify characters from the TMNIST Alphabet dataset.\n\n###  Introduction\n\nThe TMNIST Alphabet dataset is a comprehensive collection of 281,000 grayscale images, each of 28x28 pixel resolution, representing one of 94 different characters. This dataset is an excellent tool for training and evaluating machine learning models that perform character recognition tasks.\n\nCharacters included range from alphanumeric ('0'-'9', 'a'-'z', 'A'-'Z') to special symbols like punctuation marks and other common keyboard characters.\n\n###  Dataset Overview\n\nHere's a closer look at what the TMNIST Alphabet dataset includes:\n\n- **Characters**: Includes a diverse set of 94 characters:\n  - **Numbers**: '0' to '9'\n  - **Lowercase letters**: 'a' to 'z'\n  - **Uppercase letters**: 'A' to 'Z'\n  - **Special characters**: `! \" # $ % & ' ( ) * + , - . / : ; < = > ? @ [ \\ ] ^ _ \\` { | } ~`\n\n- **Data Format**: The dataset is provided in a CSV file format with the following structure:\n  - **Header**: The first row provides column headers which include `names`, `labels`, and pixel columns `1` through `784`.\n  - **Names Column**: Lists the font names used for each character image, such as `Acme-Regular` or `ZillaSlab-Bold`.\n  - **Labels Column**: Identifies the character represented in each image.\n  - **Pixel Columns**: Each of the 784 columns represents a pixel value in the 28x28 image.\n\n","metadata":{}},{"cell_type":"markdown","source":"## Image Classification on TMNIST Dataset Using CNN\n\n### 1. Input Image \n- **Description**: Start with an input image from the TMNIST dataset, typically a 28x28 pixel grayscale image of a handwritten character.\n\n### 2. Convolutional Layer üåÄ\n- **Description**: Apply several filters to the image to create feature maps. These filters detect various features such as edges, textures, and shapes specific to characters.\n- **Emoji Key**: üåÄ (represents the action of filtering across the image)\n\n### 3. Activation Function ‚ö°\n- **Description**: Implement a ReLU (Rectified Linear Unit) activation function to introduce non-linearity, enabling the network to learn complex patterns.\n- **Emoji Key**: ‚ö° (indicates activation 'firing' upon detecting significant features)\n\n### 4. Pooling Layer üé±\n- **Description**: Use max pooling to reduce the dimensionality of each feature map, making the detection of features invariant to scale and orientation.\n- **Emoji Key**: üé± (signifies selecting the strongest feature signals like choosing the best ball in pool)\n\n### 5. Flattening Layer üî®\n- **Description**: Flatten the pooled feature maps into a single long vector to prepare them for the fully connected layer.\n- **Emoji Key**: üî® (depicts the action of flattening the data into a 1D vector)\n\n### 6. Fully Connected Layer (Dense Layer) üåê\n- **Description**: A dense layer that connects every input to every output within its layer, responsible for classifying the image into one of the 94 character categories based on the learned features.\n- **Emoji Key**: üåê (illustrates a dense network of connections)\n\n### 7. Output Layer üéØ\n- **Description**: The final layer uses softmax activation to output a probability distribution over the 94 classes, where each class corresponds to a different character.\n- **Emoji Key**: üéØ (targets the most likely character prediction)\n\n### 8. Prediction üèÜ\n- **Description**: The character corresponding to the highest probability is selected as the predicted output, completing the classification process.\n- **Emoji Key**: üèÜ (celebrates the successful prediction of the character)\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2024-04-15T18:34:11.659950Z","iopub.execute_input":"2024-04-15T18:34:11.660458Z","iopub.status.idle":"2024-04-15T18:34:11.684866Z","shell.execute_reply.started":"2024-04-15T18:34:11.660425Z","shell.execute_reply":"2024-04-15T18:34:11.683785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setting Up Our Environment\nHere, we discuss the necessary Python libraries and tools required for this project, including TensorFlow, Keras, NumPy, and Pandas. Installation commands and verification of the environment setup are covered to ensure all necessary tools are ready for use.","metadata":{}},{"cell_type":"code","source":"!pip install numpy\n!pip install tensorflow\n!pip install keras\n!pip install pandas\n!pip install seaborn","metadata":{"execution":{"iopub.status.busy":"2024-04-15T18:34:11.689646Z","iopub.execute_input":"2024-04-15T18:34:11.690064Z","iopub.status.idle":"2024-04-15T18:35:26.957468Z","shell.execute_reply.started":"2024-04-15T18:34:11.690037Z","shell.execute_reply":"2024-04-15T18:35:26.955376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.utils import shuffle\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Initialize TensorFlow and Keras components\nmodel = Sequential([\n    Conv2D(32, kernel_size=3, activation='relu', input_shape=(28,28,1)),\n    MaxPooling2D(pool_size=2),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dense(94, activation='softmax')\n])\n\n# Configure the model's optimizer and metrics\nmodel.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Data preparation utilities\nencoder = OneHotEncoder(sparse=False)\nlabel_binarizer = LabelBinarizer()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T18:35:26.959791Z","iopub.execute_input":"2024-04-15T18:35:26.960245Z","iopub.status.idle":"2024-04-15T18:35:27.074788Z","shell.execute_reply.started":"2024-04-15T18:35:26.960208Z","shell.execute_reply":"2024-04-15T18:35:27.072533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading\nThis step involves loading the TMNIST dataset from a CSV file. We demonstrate how to read the data using Pandas, display the structure of the dataset, and verify that the data is loaded correctly by viewing the first few rows.","metadata":{}},{"cell_type":"code","source":"# Import the necessary libraries for data handling\nimport pandas as pd\n\n# Define the path to the dataset, adjust as necessary for your specific environment\ndata_file_path = '/kaggle/input/tmnist-alphabet-94-characters/94_character_TMNIST.csv'\n\n# Load the dataset from the specified file path\ndata_frame = pd.read_csv(data_file_path)\n\n# Display the first five rows of the dataset to verify it's loaded correctly\ndata_frame.head(5)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T18:35:27.081616Z","iopub.execute_input":"2024-04-15T18:35:27.082563Z","iopub.status.idle":"2024-04-15T18:36:08.078960Z","shell.execute_reply.started":"2024-04-15T18:35:27.082514Z","shell.execute_reply":"2024-04-15T18:36:08.077715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's extract and display all unique values from the 'labels' column of a DataFrame, showing the distinct characters or classes. Let's also calculate and print the total number of these unique classes, indicating the variety in the dataset.","metadata":{}},{"cell_type":"markdown","source":"## Data Exploration\nIn this section, we identify and list all unique characters in the dataset. We also calculate and display the total number of distinct classes, which is crucial for understanding the scope of the classification task.\n\n","metadata":{}},{"cell_type":"code","source":"# Extract and display the distinct characters from the 'labels' column\ndistinct_labels = data_frame['labels'].unique()\nprint(\"Distinct characters in dataset:\", distinct_labels)\n\n# Determine and print the count of unique character classes in the dataset\nclass_count = data_frame['labels'].nunique()\nprint(f\"Total number of distinct character classes: {class_count}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T18:36:08.080819Z","iopub.execute_input":"2024-04-15T18:36:08.081846Z","iopub.status.idle":"2024-04-15T18:36:08.133283Z","shell.execute_reply.started":"2024-04-15T18:36:08.081806Z","shell.execute_reply":"2024-04-15T18:36:08.131654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Cleaning\nAlthough the TMNIST dataset is typically clean, this step involves checking for any missing or inconsistent data. We would handle missing values, incorrect labels, and any anomalies found in the dataset. Here, we also ensure that all feature data is numeric, converting any non-numeric entries and handling missing values appropriately.\n\n","metadata":{}},{"cell_type":"code","source":"# Separate the feature data and target labels from the dataset\nfeatures = data_frame.drop(columns=['labels'])  # Remove the 'labels' column to isolate the features\ntargets = data_frame['labels']                  # Isolate the 'labels' column as the target variable\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T18:36:08.135269Z","iopub.execute_input":"2024-04-15T18:36:08.135664Z","iopub.status.idle":"2024-04-15T18:36:09.585697Z","shell.execute_reply.started":"2024-04-15T18:36:08.135634Z","shell.execute_reply":"2024-04-15T18:36:09.584658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming there's a redundant first column in feature data that should be removed\nfeature_data = features.iloc[:, 1:]  # Adjust to exclude the first column if not needed\n\n# Setting up the plotting area for displaying images\nplot_area, plot_axes = plt.subplots(nrows=8, ncols=8, figsize=(20, 10))\nplot_area.suptitle(\"Sample Character Images from TMNIST\", fontsize=20)\n\n# Display each character image using a 'viridis' colormap for better visualization\nfor index, axis in enumerate(plot_axes.flat):\n    # Reshape feature data into 28x28 array for image display\n    character_image = axis.imshow(feature_data.values[index].reshape(28, 28), cmap='viridis')\n    axis.set_title(str(targets.iloc[index]), fontsize=14)\n\n# Adjust subplot layout to prevent overlap and ensure clarity\nplt.subplots_adjust(hspace=0.4, wspace=0.4)\n\n# Include a colorbar to illustrate the color mapping used in images\ncolor_bar = plot_area.colorbar(character_image, ax=plot_axes.ravel().tolist(), orientation='horizontal', fraction=0.05, pad=0.1)\ncolor_bar.ax.tick_params(labelsize=14)\n\n# Render the visualizations\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T18:36:09.587231Z","iopub.execute_input":"2024-04-15T18:36:09.588113Z","iopub.status.idle":"2024-04-15T18:36:21.945337Z","shell.execute_reply.started":"2024-04-15T18:36:09.588066Z","shell.execute_reply":"2024-04-15T18:36:21.939936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data_frame.drop(columns=['labels'])\ny = data_frame['labels']","metadata":{"execution":{"iopub.status.busy":"2024-04-15T18:36:21.950781Z","iopub.execute_input":"2024-04-15T18:36:21.953110Z","iopub.status.idle":"2024-04-15T18:36:26.641419Z","shell.execute_reply.started":"2024-04-15T18:36:21.952963Z","shell.execute_reply":"2024-04-15T18:36:26.638145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=32,stratify=y)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T18:36:26.643775Z","iopub.execute_input":"2024-04-15T18:36:26.644239Z","iopub.status.idle":"2024-04-15T18:36:39.161234Z","shell.execute_reply.started":"2024-04-15T18:36:26.644202Z","shell.execute_reply":"2024-04-15T18:36:39.152976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install squarify\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T18:36:39.175499Z","iopub.execute_input":"2024-04-15T18:36:39.176577Z","iopub.status.idle":"2024-04-15T18:36:56.281280Z","shell.execute_reply.started":"2024-04-15T18:36:39.176502Z","shell.execute_reply":"2024-04-15T18:36:56.279271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate counts for each class\ntrain_counts = y_train.value_counts().sort_index()\ntest_counts = y_test.value_counts().sort_index()\n\n# Normalize counts to fit the area of the treemap (area is typically set to 100 or 1 for simplicity)\ntrain_norm = train_counts / train_counts.sum() * 100\ntest_norm = test_counts / test_counts.sum() * 100\n\n# Create a DataFrame for better handling\ntrain_df = pd.DataFrame({'label': train_counts.index, 'size': train_norm})\ntest_df = pd.DataFrame({'label': test_counts.index, 'size': test_norm})\n\n# Plotting\nfig, ax = plt.subplots(2, 1, figsize=(16, 12))\n\n# Treemap for training data\nsquarify.plot(sizes=train_df['size'], label=train_df['label'], alpha=.8, ax=ax[0])\nax[0].set_title('Treemap of Class Distribution in Train Data')\nax[0].axis('off')  # Hide the axes\n\n# Treemap for testing data\nsquarify.plot(sizes=test_df['size'], label=test_df['label'], alpha=.8, ax=ax[1])\nax[1].set_title('Treemap of Class Distribution in Test Data')\nax[1].axis('off')  # Hide the axes\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T18:36:56.283825Z","iopub.execute_input":"2024-04-15T18:36:56.284242Z","iopub.status.idle":"2024-04-15T18:36:57.502707Z","shell.execute_reply.started":"2024-04-15T18:36:56.284210Z","shell.execute_reply":"2024-04-15T18:36:57.501644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normalization: \nScaling the pixel values to a range of 0 to 1 to facilitate more efficient training by standardizing the input scale.\n","metadata":{}},{"cell_type":"code","source":"# Select numeric columns only from both training and testing data using a broad numeric type filter\nX_train_numeric = X_train.select_dtypes(include=[np.number])  # Simplifies the selection to include all numeric types\nX_test_numeric = X_test.select_dtypes(include=[np.number])\n\n# Ensure all data in these columns is numeric, converting any non-numeric entries to NaN\nX_train_numeric = X_train_numeric.apply(lambda x: pd.to_numeric(x, errors='coerce'))\nX_test_numeric = X_test_numeric.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n\n# Replace any NaN values that resulted from the conversion with zero\nX_train_numeric.fillna(0, inplace=True)\nX_test_numeric.fillna(0, inplace=True)\n\n# Normalize the numeric data to range between 0 and 1 for use in machine learning models\nX_train_normalized = X_train_numeric.astype('float32') / 255\nX_test_normalized = X_test_numeric.astype('float32') / 255","metadata":{"execution":{"iopub.status.busy":"2024-04-15T18:36:57.504148Z","iopub.execute_input":"2024-04-15T18:36:57.504695Z","iopub.status.idle":"2024-04-15T18:37:06.051980Z","shell.execute_reply.started":"2024-04-15T18:36:57.504666Z","shell.execute_reply":"2024-04-15T18:37:06.050987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract the first few features for visualization\nfirst_few_features = X_train.iloc[:, :4]  # Adjust the number of features as needed\n\n# Create scatter plots for each pair of features\nplt.figure(figsize=(12, 8))  # Adjust the figure size for better clarity\nfor i in range(len(first_few_features.columns)):\n    for j in range(i+1, len(first_few_features.columns)):\n        plt.subplot(2, 3, j - i)\n        plt.scatter(first_few_features.iloc[:, i], first_few_features.iloc[:, j], alpha=0.5)\n        plt.xlabel(first_few_features.columns[i])\n        plt.ylabel(first_few_features.columns[j])\nplt.suptitle('Scatter Plots of the First Few Features', size=20, y=1.02)\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T18:37:06.053123Z","iopub.execute_input":"2024-04-15T18:37:06.053493Z","iopub.status.idle":"2024-04-15T18:38:14.296282Z","shell.execute_reply.started":"2024-04-15T18:37:06.053453Z","shell.execute_reply":"2024-04-15T18:38:14.294779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filter out non-numeric columns to include only numeric data for correlation analysis, considering the first 10 numeric columns\nnumeric_cols = X_train.select_dtypes(include=[np.number]).iloc[:, :10]\n\n# Compute the correlation matrix for the selected numeric features\ncorrelation_matrix = numeric_cols.corr()\n\n# Visualize the correlations using a heatmap\nplt.figure(figsize=(10, 8))  # Adjust the figure size for clarity\nsns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", linewidths=.5, cmap='viridis', vmin=-1, vmax=1)\nplt.title('Correlation Matrix of Numeric Features', fontsize=18)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T03:39:10.595189Z","iopub.execute_input":"2024-04-15T03:39:10.595530Z","iopub.status.idle":"2024-04-15T03:39:11.672598Z","shell.execute_reply.started":"2024-04-15T03:39:10.595502Z","shell.execute_reply":"2024-04-15T03:39:11.671437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enc = OneHotEncoder(sparse=False,handle_unknown='ignore')\ny_train_encoded=enc.fit_transform(y_train.values.reshape(-1,1))\ny_test_encoded=  enc.transform(y_test.values.reshape(-1,1))","metadata":{"execution":{"iopub.status.busy":"2024-04-15T03:39:11.674425Z","iopub.execute_input":"2024-04-15T03:39:11.675211Z","iopub.status.idle":"2024-04-15T03:39:11.814685Z","shell.execute_reply.started":"2024-04-15T03:39:11.675166Z","shell.execute_reply":"2024-04-15T03:39:11.813394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sum up occurrences of each class in the encoded arrays\ny_train_sum = y_train_encoded.sum(axis=0)\ny_test_sum = y_test_encoded.sum(axis=0)\n\n# Get the class labels from the encoder\nclass_labels = enc.get_feature_names_out(input_features=['Class'])\n\ndef plot_grouped_bar_chart(class_sums_train, class_sums_test, class_labels, title):\n    \"\"\"\n    Plot the class distributions as a grouped bar chart.\n    \n    Parameters:\n    - class_sums_train: Array of sums of occurrences for each class in the training set\n    - class_sums_test: Array of sums of occurrences for each class in the testing set\n    - class_labels: Labels of the classes\n    - title: Title for the plot\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(14, 8))\n    bar_width = 0.35  # Width of the bars\n    index = np.arange(len(class_labels))  # The label locations\n    \n    # Creating bars for training and testing sets\n    bars_train = ax.bar(index - bar_width/2, class_sums_train, bar_width, label='Training', color='skyblue')\n    bars_test = ax.bar(index + bar_width/2, class_sums_test, bar_width, label='Testing', color='orange')\n    \n    ax.set_title(title, fontsize=20)\n    ax.set_xlabel('Classes', fontsize=16)\n    ax.set_ylabel('Occurrences', fontsize=16)\n    ax.set_xticks(index)\n    ax.set_xticklabels(class_labels, rotation=45, ha=\"right\")\n    ax.legend()\n\n    # Adding the text labels on the bars\n    for bars in [bars_train, bars_test]:\n        for bar in bars:\n            height = bar.get_height()\n            ax.annotate('{}'.format(height),\n                        xy=(bar.get_x() + bar.get_width() / 2, height),\n                        xytext=(0, 3),  # 3 points vertical offset\n                        textcoords=\"offset points\",\n                        ha='center', va='bottom')\n\n    plt.tight_layout()\n    plt.show()\n\n# Assuming 'y_train_sum', 'y_test_sum', and 'class_labels' are defined as from previous implementations\nplot_grouped_bar_chart(y_train_sum, y_test_sum, class_labels, 'Class Distribution in Training and Testing Set')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T03:39:11.816288Z","iopub.execute_input":"2024-04-15T03:39:11.816672Z","iopub.status.idle":"2024-04-15T03:39:14.298400Z","shell.execute_reply.started":"2024-04-15T03:39:11.816639Z","shell.execute_reply":"2024-04-15T03:39:14.297010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Overview of Configuring and Training a CNN with TensorFlow Keras\nThis guide provides a comprehensive overview of preparing, configuring, and training a convolutional neural network (CNN) using TensorFlow's Keras API for image classification tasks.\n\n**Model Configuration:**\nThe CNN model is set up using a sequential architecture, which includes multiple layers:\n\n**Reshape Layer:** Adjusts input dimensions to suit the model's requirements.\nConvolutional Layers (Conv2D): Extracts features from the input images using filters, applying ReLU activation.\n\n**Batch Normalization:** Stabilizes learning by normalizing the activation of the previous layer.\n\n**Max Pooling Layers:** Reduces dimensionality which helps in reducing computational complexity and overfitting.\n\n**Dropout Layers:** Prevents overfitting by randomly setting input units to 0 during training at each update cycle.\n\n**Flatten Layer:** Converts pooled feature maps into a single column that is passed to the fully connected layer.\n\n**Dense Layers:** Fully connected layers that learn non-linear combinations of the high-level features extracted by the convolutional layers.\n\n**Output Layer:** Uses softmax activation to output a probability distribution over the target classes.\n\n**Compilation of the Model:**\nThe model is compiled with:\n\n**Optimizer:** Adam, an efficient stochastic gradient descent algorithm.\nLoss Function: Categorical crossentropy, suitable for multi-class classification tasks.\nMetrics: Accuracy, to evaluate the performance during training and testing.\n\n**Data Preparation:**\n\nEncoding Labels: Labels are transformed into a one-hot encoded format to fit the output layer using an OneHotEncoder.\nFeature Scaling: Image data features are scaled (normalized) by dividing pixel values by 255 to range between 0 and 1, enhancing model training efficiency.\n\n**Model Training:**\n\nThe model is trained on preprocessed images and labels, using a portion of the data for validation to monitor performance and avoid overfitting.\nTraining involves multiple epochs where the model iteratively adjusts its parameters (weights and biases) to minimize the loss.\n\n**Model Evaluation and Visualization:**\n\nAfter training, the model's structure and performance can be visualized using plot_model, which saves a diagram of the model's architecture.\nPerformance on the training set is evaluated to confirm the model is trained properly without overfitting.\nThis workflow encapsulates the complete process from model architecture design, through data preprocessing, to training and evaluation, suitable for tackling complex image classification problems with high efficacy.\n\n","metadata":{}},{"cell_type":"code","source":"# Assuming the extra feature is the last column, you can exclude it like this:\nX_train_pixels = X_train.iloc[:, :-1]  # Exclude the last column\nX_test_pixels = X_test.iloc[:, :-1]    # Exclude the last column\n\n# Now, you can safely reshape the pixel data to (28, 28) format\nX_train_norm = X_train_pixels.values.reshape(-1, 28, 28)\nX_test_norm = X_test_pixels.values.reshape(-1, 28, 28)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T03:39:14.300388Z","iopub.execute_input":"2024-04-15T03:39:14.301160Z","iopub.status.idle":"2024-04-15T03:39:28.987421Z","shell.execute_reply.started":"2024-04-15T03:39:14.301111Z","shell.execute_reply":"2024-04-15T03:39:28.986201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary layers and functions from Keras\nfrom tensorflow.keras.layers import Reshape, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\n\n# Calculate the number of unique classes in the dataset\nno_of_classes = data_frame['labels'].nunique()\n\n# Define the model using the Sequential API, which allows adding layers in a stack\nmodel_new = Sequential([\n    # First reshape the input to ensure the model gets the right dimension\n    Reshape((28,28,1), input_shape=(28,28)),\n    \n    # First convolutional layer with 64 filters of size 3x3, ReLU activation, and 'same' padding\n    Conv2D(64, (3,3), activation='relu', padding='same'),\n    \n    # Batch normalization to maintain the mean output close to 0 and the output standard deviation close to 1\n    BatchNormalization(),\n    \n    # Max pooling layer to reduce spatial dimensions (width and height)\n    MaxPooling2D((2,2)),\n    \n    # Dropout layer to reduce overfitting by dropping out units randomly during training\n    Dropout(0.25),\n    \n    # Second convolutional layer with 128 filters, ReLU activation, and 'same' padding\n    Conv2D(128, (3,3), activation='relu', padding='same'),\n    \n    # Batch normalization layer\n    BatchNormalization(),\n    \n    # Second max pooling layer\n    MaxPooling2D((2,2)),\n    \n    # Dropout layer\n    Dropout(0.25),\n    \n    # Third convolutional layer with 256 filters\n    Conv2D(256, (3,3), activation='relu', padding='same'),\n    \n    # Batch normalization layer\n    BatchNormalization(),\n    \n    # Third max pooling layer\n    MaxPooling2D((2,2)),\n    \n    # Dropout layer\n    Dropout(0.25),\n    \n    # Flatten the output of the previous layer to a single vector\n    Flatten(),\n    \n    # Fully connected (dense) layer with 512 units and ReLU activation\n    Dense(512, activation='relu'),\n    \n    # Batch normalization layer\n    BatchNormalization(),\n    \n    # Dropout layer\n    Dropout(0.5),\n    \n    # Another dense layer with 256 units\n    Dense(256, activation='relu'),\n    \n    # Batch normalization layer\n    BatchNormalization(),\n    \n    # Dropout layer\n    Dropout(0.5),\n    \n    # Another dense layer with 128 units\n    Dense(128, activation='relu'),\n    \n    # Batch normalization layer\n    BatchNormalization(),\n    \n    # Dropout layer\n    Dropout(0.5),\n    \n    # Dense layer with 32 units\n    Dense(32, activation='relu'),\n    \n    # Output layer with a unit for each class, using softmax to achieve a probability distribution\n    Dense(no_of_classes, activation='softmax')\n])\n\n# Define the optimizer, Adam, with a learning rate of 0.001\nopt = Adam(lr=0.001)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T03:41:09.419252Z","iopub.execute_input":"2024-04-15T03:41:09.420134Z","iopub.status.idle":"2024-04-15T03:41:09.797764Z","shell.execute_reply.started":"2024-04-15T03:41:09.420089Z","shell.execute_reply":"2024-04-15T03:41:09.796509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\n\nmodel_new.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel_new.summary()\n\n# For a graphical representation\nplot_model(model_new, to_file='model_new.png', show_shapes=True, show_layer_names=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T03:41:19.311535Z","iopub.execute_input":"2024-04-15T03:41:19.312042Z","iopub.status.idle":"2024-04-15T03:41:21.112129Z","shell.execute_reply.started":"2024-04-15T03:41:19.312004Z","shell.execute_reply":"2024-04-15T03:41:21.110871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the neural network model\nmodel_new.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel_new.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-15T03:41:30.213706Z","iopub.execute_input":"2024-04-15T03:41:30.215142Z","iopub.status.idle":"2024-04-15T03:41:30.308468Z","shell.execute_reply.started":"2024-04-15T03:41:30.215077Z","shell.execute_reply":"2024-04-15T03:41:30.306453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model with specified optimizer, loss function, and metrics\nmodel_new.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Display the summary of the model\nmodel_new.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T03:44:12.223446Z","iopub.execute_input":"2024-04-15T03:44:12.224068Z","iopub.status.idle":"2024-04-15T03:44:12.346774Z","shell.execute_reply.started":"2024-04-15T03:44:12.224024Z","shell.execute_reply":"2024-04-15T03:44:12.344722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encode the labels to one-hot format\nencoder = OneHotEncoder(sparse=False)\ny_encoded = encoder.fit_transform(data_frame['labels'].values.reshape(-1, 1))\n\nX = data_frame.drop(columns=['names', 'labels'])\n\n# Now convert this to numpy arrays and reshape it assuming each image is 28x28 pixels\nX = X.values.reshape(-1, 28, 28, 1).astype('float32') / 255  # Normalize pixel values by dividing by 255\n\n# Now, your X_train_norm and X_test_norm should be set as follows:\nX_train_norm, X_test_norm, y_train_encoded, y_test_encoded = train_test_split(X, y_encoded, test_size=0.2, random_state=32)\n\n# You can now proceed to fit your model:\nmodel_history = model_new.fit(X_train_norm, y_train_encoded, epochs=10, validation_data=(X_test_norm, y_test_encoded), verbose=2, batch_size=128)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T03:49:18.609424Z","iopub.execute_input":"2024-04-15T03:49:18.610084Z","iopub.status.idle":"2024-04-15T05:43:10.518465Z","shell.execute_reply.started":"2024-04-15T03:49:18.610037Z","shell.execute_reply":"2024-04-15T05:43:10.514151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the training data\n# 'evaluate' function returns the loss value & metrics values for the model in test mode\n# 'batch_size' defines the number of samples per gradient update\n# 'verbose=0' means silent mode, no output will be printed during the evaluation process\nscore = model_new.evaluate(X_train_norm, y_train_encoded, batch_size=64, verbose=0)\n\n# Extract the accuracy part of the score and format it to percentage with 4 decimal places\n# 'score[1]' generally refers to accuracy if the model.compile metrics parameter is set to ['accuracy']\nprint(f\"Test Accuracy: {round(score[1], 4) * 100}%\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T05:50:47.338058Z","iopub.execute_input":"2024-04-15T05:50:47.340788Z","iopub.status.idle":"2024-04-15T05:53:27.318714Z","shell.execute_reply.started":"2024-04-15T05:50:47.340665Z","shell.execute_reply":"2024-04-15T05:53:27.317356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extracting values from the history object\nepochs = range(1, len(model_history.history['accuracy']) + 1)\ntrain_accuracy = model_history.history['accuracy']\nval_accuracy = model_history.history['val_accuracy']\ntrain_loss = model_history.history['loss']\nval_loss = model_history.history['val_loss']  # Extract validation loss\n\n# Plotting Epoch vs Accuracy\nplt.figure(figsize=(14, 8))\nplt.subplot(2, 2, 1)  # 2 rows, 2 columns, 1st subplot\nplt.plot(epochs, train_accuracy, 'bo-', label='Training Accuracy')\nplt.plot(epochs, val_accuracy, 'ro-', label='Validation Accuracy')\nplt.title('Epoch vs Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Plotting Loss vs Accuracy\nplt.subplot(2, 2, 2)  # 2 rows, 2 columns, 2nd subplot\nplt.plot(train_loss, train_accuracy, 'go-', label='Training')\nplt.title('Loss vs Accuracy')\nplt.xlabel('Loss')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Plotting Epoch vs Loss\nplt.subplot(2, 2, 3)  # 2 rows, 2 columns, 3rd subplot\nplt.plot(epochs, train_loss, 'b^-', label='Training Loss')\nplt.plot(epochs, val_loss, 'r^-', label='Validation Loss')\nplt.title('Epoch vs Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()  # Adjust layout to prevent overlap\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T05:55:42.593345Z","iopub.execute_input":"2024-04-15T05:55:42.593982Z","iopub.status.idle":"2024-04-15T05:55:43.643168Z","shell.execute_reply.started":"2024-04-15T05:55:42.593934Z","shell.execute_reply":"2024-04-15T05:55:43.641587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion\nModel Training and Validation Performance\nTraining and Validation Accuracy:\n\nThe model shows a steady increase in both training and validation accuracy over 10 epochs. Starting from an initial accuracy of 64.5% on training data, it improved to 92.36% by the 10th epoch. Validation accuracy also improved consistently, beginning at 88.35% and reaching 93.98%.\nThis consistent improvement in accuracy suggests that the model is learning effectively from the training data and generalizing well to the unseen validation data.\nTraining and Validation Loss:\n\nBoth training and validation loss decreased significantly across epochs, indicating a good convergence of the model. The training loss dropped from 1.3018 to 0.2540, while validation loss decreased from 0.4076 to 0.1937.\nThe closeness of training and validation loss values by the end of the training indicates that the model is not overfitting significantly. The model maintains a good balance between bias and variance.\nModel Evaluation\nThe evaluation on the training data after training completion showed an **accuracy of approximately 94.7%.** This high accuracy rate on the training set, closely matching the validation accuracy, further confirms the model's robustness and its ability to generalize beyond just the training dataset.\nVisualization Insights\nThe plots of Epoch vs. Accuracy and Epoch vs. Loss provide visual confirmation of the model's steady improvement and stability. The plots do not show any erratic changes in accuracy or loss, which often indicate problems like learning rate issues or data inconsistencies.\n\nThe Loss vs. Accuracy plot for the training set, although less common in reporting results, suggests that as the model's loss decreases, its ability to correctly classify the training data increases, as expected.\n\nConclusions\nThe model is well-tuned for the task with a suitable architecture (depth and breadth of layers) and hyperparameters (learning rate, batch size). The use of dropout and batch normalization layers has effectively helped in managing overfitting and ensuring stable training dynamics.\n\nThere is room for potential improvement. Experimenting with further tuning of the learning rate, increasing the model complexity, or implementing advanced techniques like data augmentation or different regularization methods might yield even better results.\n\nThe CNN has proven to be effective for the classification of complex patterns in image data, as evidenced by its performance on the TMNIST dataset with 94 classes, making it a good choice for similar tasks in image recognition.\n\nIn summary, the CNN model has demonstrated strong performance characteristics in this scenario, and with minor adjustments, it could potentially be improved further. This model serves as a robust baseline for further experimentation and refinement.\n\n\n## Citations and Licensing\n\nMajority of the techniques have been adapted from the following notebook\nLink - https://www.kaggle.com/datasets/nikbearbrown/tmnist-alphabet-94-characters/code \n\nhttps://github.com/aiskunks/Skunks_Skool\n\nhttps://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939 , \n\nhttps://towardsdatascience.com/recurrent-neural-networks-rnns-3f06d7653a85\n\n\n\n\nCopyright (c) 2023 Palak Rajdev\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nDisclaimer: The Software is provided \"AS IS\", without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose, and non-infringement. In no event shall the author or copyright holders be liable for any claim, damages, or other liability, whether in an action of contract, tort or otherwise, arising from, out of, or in connection with the Software or the use or other dealings in the Software.\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}